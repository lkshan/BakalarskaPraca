\chapter*{Záver}  % chapter* je necislovana kapitola
\addcontentsline{toc}{chapter}{Záver} % rucne pridanie do obsahu
\markboth{Záver}{Záver} % vyriesenie hlaviciek

Ako sme už mnohokrát spomenuli, cieľom tejto práce je odpozorovať vplyv implementácie syntetického gradientu na priebeh trénovania neurónovej siete. S myšlienkou implementácie jednoduchých neurónových sieti trénovaných na predikciu hodnoty gradientu prišla organizácia DeepMind, divízia spoločnosti Google orientovaná vo výskume umelej inteligencie. V súčastnosti bola metóda syntetického gradientu experimentálne integrovaná predovšetkým v jednoduchých dopredných neurónových sieťach, rekurentných neurónových sieťach a konvolučných neurónových sieťach.
Pozorovať vplyv implementácie syntetického gradientu v reziduálnych sieťach sme sa rozhodli preto, lebo doposiaľ sa nepodarilo nájsť žiaden zdokumentovaný experiment, kde by bola metóda syntetického gradientu implementovaná práve v reziduálnych sieťach. Zamerali sme sa predovšetkým na nahradenie pôvodnej reziduálnej siete MMD-ResNet použitej na kalibráciu vzoriek pri automatickom gatovaní buniek cytometrickej dátovej sady, metódou DeepCyTOF.

Výsledkami experimentov, opísaných v Kap. \ref{vysledky}, sme sa snažili preukázať zmeny v procese trénovania MMD-ResNet využívajúcej metódu syntetického gradientu v porovnaní s procesom trénovania MMD-ResNet využívajúcej metódu spätného šírenia chyby. Zamerali sme sa predovšetkým na vývoj hodnoty chybovej funkcie v čase trénovania a v jednotlivých iteráciách trénovania. Sekundárne sme pozorovali aj vplyv implementácie syntetického gradientu na presnosť kalibrácie MMD-ResNet, ktorú sme merali metrikou \textit{F1 skóre}.

Výsledky experimentov opísaných v Kap. \ref{vyvoj_MMD_v_iteraciach}, poukazujú na skutočnosť, že implementáciou syntetického gradientu do MMD-ResNet je možné dosiahnuť rovnakú hodnotu chybovej funkcie ako v prípade MMD-ResNet využívajúca štandardnú metódu spätného šírenia chyby. Implementácia syntetického gradientu do MMD-ResNet zapríčiňuje zníženie miery konvergencie hodnoty chybovej funkcie v porovnaní s MMD-ResNet využívajúcej metódu spätného šírenia chyby. Preto pri trénovaní MMD-ResNet metódou syntetického gradientu je potrebné vykonať viacej iterácií trénovania (približne o $25\%$) pre dosiahnutie rovnakej hodnoty chybovej funkcie ako v prípade MMD-ResNet využívajúcej metódu spätného šírenia chyby.

Nižšia miera konvergencie hodnoty chybovej funkcie pri trénovaní MMD-ResNet využívajúcej metódu syntetického gradientu je zapríčinená práve aproximáciou skutočného gradientu (viď Kap. \ref{vyvoj_MMD_v_iteraciach}). V tomto prípade sa miera konvergencie odvíja práve od toho, že jednotlivé skryté vrstvy MMD-ResNet nie sú trénované skutočným gradientom ale jeho aproximáciou, ktorá nie je úplne presná. 

V ďalšom experimente sme sa zamerali predovšetkým na čas potrebný na dosiahnutie optimálnej hodnoty MMD pri implementácii syntetického gradientu v MMD-ResNet. Optimálna hodnota MMD v tomto kontexte predstavuje bod v ktorom sa MMD-ResNet \textit{„prestáva učiť“}, resp. vývoj hodnoty chybovej funkcie naberá stagnujúci trend. Na základe experimentu opísaného v Kap. \ref{vyvoj_MMD_v_case} je možné vidieť, že aj napriek nižšej miere konvergencie hodnoty chybovej funkcie pri MMD-ResNet využívajúcej metódu syntetického gradientu je optimálna hodnota MMD nadobudnutá časovo rýchlejšie ako v prípade MMD-ResNet využívajúcej metódu spätného šírenia chyby.

Zníženie času potrebného na nadobudnutie optimálnej hodnoty je zabezpečené paralelným trénovaním jednotlivých skrytých vrstiev MMD-ResNet využívajúcej metódu syntetického gradientu. V prípade experimentu opísaného v Kap. \ref{vyvoj_MMD_v_case} je rozdiel času potrebného na dosiahnutie optimálnej hodnoty medzi MMD-ResNet využívajúcej metódu syntetického gradientu a MMD-ResNet využívajúcej metódu spätného šírenia chyby len 5 sekúnd. Tento rozdiel nie je signifikantný vzhľadom na celkovú dĺžku trvania trénovania daných modelov. V prípade trénovania MMD-ResNet na väčšom počte iterácií, rozdiel v čase dosiahnutia optimálnej hodnoty MMD narastá lineárne.

Smerodajná metrika vyhodnotenia presnosti kalibrácie MMD-ResNet je \textit{F1 skóre} dosiahnuté pri automatickom gatovaní kalibrovaných vzoriek. Pomocou jednoduchej funkcie ladenia hyperparametrov sa nám pri automatickom gatovaní vzoriek kalibrovaných pomocou MMD-ResNet využívajúcej metódu syntetického gradientu podarilo dosiahnuť \textit{F1 skóre} až 0,836. Zdroj \cite{Li2017} uviedol, že pôvodná implementácia metódy DeepCyTOF zabezpečuje \textit{F1 skóre} až 0,976. Na základe našich výsledkov je možné vyjadriť signifikantný pokles hodnoty \textit{F1 skóre} pri automatickom gatovaní vzoriek kalibrovaných pomocou MMD-ResNet využívajúcej metódu syntetického gradientu.

Domnievame sa, že daný problém môže byť zapríčinený náhodnou inicializáciou váh a parametrov jednotlivých skrytých vrstiev MMD-ResNet v korelácii s náhodnou inicializáciou váh a parametrov vrstiev modulov syntetického gradientu. Vzhľadom k tomu, že naša implementácia zahŕňa viacej prípadov náhodného inicializovania práve z dôvodu inicializovania váh modulov syntetického gradientu, tak náhodný faktor sa v tomto prípade prejavuje vo väčšej miere ako pri pôvodnej implementácii. Vplyv na pokles \textit{F1 skóre} môže mať aj chybová funkcia MMD na výstupe MMD-ResNet. Funkcia MMD vypočítava hodnotu MMD medzi bunkami obsiahnutými v trénovacej dávke a náhodne vybranými bunkami z referenčnej vzorky. Vzhľadom k tomu, že výber buniek z referenčnej vzorky je náhodný, tak výsledok funkcie je ovplyvnený istým stochastickým faktorom. Tento faktor má priamy vplyv na hodnotu gradientu vypočítaného z výsledku chybovej funkcie, ktorý je následne použitý na výpočet gradientu pre jednotlivé moduly syntetického gradientu.

Výsledky implementácie syntetického gradientu v MMD-ResNet boli získavané v komplexnejšom prostredí ako uvádzajú zdroje \cite{Jaderberg2016, Czarnecki2017}. Zdroje uvádzajú implementáciu metódy syntetického gradientu v prostrediach, kde presnosť pozorovaného modelu nie je podmienená výsledkami iného modelu. V našom prípade je MMD-ResNet trénovaná za účelom znižovania hodnoty MMD medzi zdrojovými vzorkami a referenčnou vzorkou. Smerodajný ukazovateľ presnosti MMD-ResNet je však výsledok automatického gatovania vzoriek kalibrovaných pomocou tohto modelu.

Rozdiel výsledkov MMD-ResNet využívajúcej metódu syntetického gradientu v porovnaní s MMD-ResNet využívajúcej metódu spätného šírenia chyby vznika pri pri finálnej klasifikácii vzoriek kalibrovaných týmito modelmi. Tento problém sa však týka len našej problémovej domény a je ho možné riešiť dôkladnejším ladením hyperparametrov MMD-ResNet využívajúcej metódu syntetického gradientu.

Iné reziduálne siete nemajú problém poklesu presnosti predikcie v prípade implementácie syntetického gradientu vzhľadom k tomu, že ich výstup sa neposiela inému modelu neurónovej siete na vyhodnotenie. V našom prípade nevieme ovplyvniť trénovanie MMD-ResNet tak, aby pri trénovaní bola braná do úvahy aj hodnota MMD a aj hodnota \textit{F1 skóre} získaná pri klasifikácii kalibrovaných vzoriek v danej iterácii trénovania MMD-ResNet. Vo finále obidva modely MMD-ResNet dosahujú rovnakú hodnotu chybovej funkcie, resp. hodnotu MMD. Na základe tejto skutočnosti je možné povedať, že reziduálne siete trénované metódou syntetického gradientu sú schopné nadobúdať porovnateľné výsledky a to za predpokladu nižšieho množstva času potrebného na ich trénovanie, v porovnaní s reziduálnymi sieťami trénovanými metódou spätného šírenia chyby.

Na základe analýzy všetkých experimentov opísaných v Kap. \ref{vysledky} sme zistili, že implementácia syntetického gradientu v MMD-ResNet zapríčiňuje zníženie miera konvergencie hodnoty chybovej funkcie. Tento problém je riešený zvýšením počtu iterácií trénovania MMD-ResNet využívajúcej metódu syntetického gradientu. Aj napriek nižšej miere konvergencie je čas trénovania MMD-ResNet využívajúcej metódu syntetického gradientu nižší v porovnaní s časom trénovania MMD-ResNet využívajúcej metódu spätného šírenia chyby. Šetrenie času v tomto prípade je dosiahnuté na úkor zníženia hodnoty \textit{F1 skóre} pri finálnej klasifikácii buniek kalibrovaných touto MMD-ResNet. Domnievame sa, že pri implementácii syntetického gradientu v akejkoľvek inej reziduálnej sieti by boli dosiahnuté podobné výsledky správania reziduálnej siete v procese jej trénovania.

Na záver by sme chceli pripomenúť, že cieľom tejto práce nie je vytvorenie reziduálnej siete trénovanej metódou syntetického gradientu s vysokou mierou presnosti predikcie, resp. kalibrácie. Cieľom tejto práce je pozorovanie správania reziduálnej siete v priebehu jej trénovania pomocou metódy syntetického gradientu.